{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For getting personwise keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T07:54:50.337738Z",
     "start_time": "2019-11-25T07:54:49.820982Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "from random import randint\n",
    "\n",
    "protoFile = \"../resources/pose/coco/pose_deploy_linevec.prototxt\"\n",
    "weightsFile = \"../resources/pose/coco/pose_iter_440000.caffemodel\"\n",
    "nPoints = 18\n",
    "# COCO Output Format\n",
    "keypointsMapping = ['Nose', 'Neck', 'R-Sho', 'R-Elb', 'R-Wr', 'L-Sho', \n",
    "                    'L-Elb', 'L-Wr', 'R-Hip', 'R-Knee', 'R-Ank', 'L-Hip', \n",
    "                    'L-Knee', 'L-Ank', 'R-Eye', 'L-Eye', 'R-Ear', 'L-Ear']\n",
    "\n",
    "POSE_PAIRS = [[1,2], [1,5], [2,3], [3,4], [5,6], [6,7],\n",
    "              [1,8], [8,9], [9,10], [1,11], [11,12], [12,13],\n",
    "              [1,0], [0,14], [14,16], [0,15], [15,17],\n",
    "              [2,17], [5,16] ]\n",
    "\n",
    "# index of pafs correspoding to the POSE_PAIRS\n",
    "# e.g for POSE_PAIR(1,2), the PAFs are located at indices (31,32) of output, Similarly, (1,5) -> (39,40) and so on.\n",
    "mapIdx = [[31,32], [39,40], [33,34], [35,36], [41,42], [43,44], \n",
    "          [19,20], [21,22], [23,24], [25,26], [27,28], [29,30], \n",
    "          [47,48], [49,50], [53,54], [51,52], [55,56], \n",
    "          [37,38], [45,46]]\n",
    "\n",
    "colors = [ [0,100,255], [0,100,255], [0,255,255], [0,100,255], [0,255,255], [0,100,255],\n",
    "         [0,255,0], [255,200,100], [255,0,255], [0,255,0], [255,200,100], [255,0,255],\n",
    "         [0,0,255], [255,0,0], [200,200,0], [255,0,0], [200,200,0], [0,0,0]]\n",
    "\n",
    "net = cv2.dnn.readNetFromCaffe(protoFile, weightsFile)\n",
    "\n",
    "\n",
    "def getPoseData(image1):\n",
    "    ###########################################\n",
    "    # Find the Keypoints using Non Maximum Suppression on the Confidence Map\n",
    "    def getKeypoints(probMap, threshold=0.1):\n",
    "\n",
    "        mapSmooth = cv2.GaussianBlur(probMap,(3,3),0,0)\n",
    "\n",
    "        mapMask = np.uint8(mapSmooth>threshold)\n",
    "        keypoints = []\n",
    "\n",
    "        #find the blobs\n",
    "        _, contours, _ = cv2.findContours(mapMask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        #for each blob find the maxima\n",
    "        for cnt in contours:\n",
    "            blobMask = np.zeros(mapMask.shape)\n",
    "            blobMask = cv2.fillConvexPoly(blobMask, cnt, 1)\n",
    "            maskedProbMap = mapSmooth * blobMask\n",
    "            _, maxVal, _, maxLoc = cv2.minMaxLoc(maskedProbMap)\n",
    "            keypoints.append(maxLoc + (probMap[maxLoc[1], maxLoc[0]],))\n",
    "\n",
    "        return keypoints\n",
    "\n",
    "    # Find valid connections between the different joints of a all persons present\n",
    "    def getValidPairs(output):\n",
    "        valid_pairs = []\n",
    "        invalid_pairs = []\n",
    "        n_interp_samples = 10\n",
    "        paf_score_th = 0.1\n",
    "        conf_th = 0.7\n",
    "        # loop for every POSE_PAIR\n",
    "        for k in range(len(mapIdx)):\n",
    "            # A->B constitute a limb\n",
    "            pafA = output[0, mapIdx[k][0], :, :]\n",
    "            pafB = output[0, mapIdx[k][1], :, :]\n",
    "            pafA = cv2.resize(pafA, (frameWidth, frameHeight))\n",
    "            pafB = cv2.resize(pafB, (frameWidth, frameHeight))\n",
    "\n",
    "            # Find the keypoints for the first and second limb\n",
    "            candA = detected_keypoints[POSE_PAIRS[k][0]]\n",
    "            candB = detected_keypoints[POSE_PAIRS[k][1]]\n",
    "            nA = len(candA)\n",
    "            nB = len(candB)\n",
    "\n",
    "            # If keypoints for the joint-pair is detected\n",
    "            # check every joint in candA with every joint in candB \n",
    "            # Calculate the distance vector between the two joints\n",
    "            # Find the PAF values at a set of interpolated points between the joints\n",
    "            # Use the above formula to compute a score to mark the connection valid\n",
    "\n",
    "            if( nA != 0 and nB != 0):\n",
    "                valid_pair = np.zeros((0,3))\n",
    "                for i in range(nA):\n",
    "                    max_j=-1\n",
    "                    maxScore = -1\n",
    "                    found = 0\n",
    "                    for j in range(nB):\n",
    "                        # Find d_ij\n",
    "                        d_ij = np.subtract(candB[j][:2], candA[i][:2])\n",
    "                        norm = np.linalg.norm(d_ij)\n",
    "                        if norm:\n",
    "                            d_ij = d_ij / norm\n",
    "                        else:\n",
    "                            continue\n",
    "                        # Find p(u)\n",
    "                        interp_coord = list(zip(np.linspace(candA[i][0], candB[j][0], num=n_interp_samples),\n",
    "                                                np.linspace(candA[i][1], candB[j][1], num=n_interp_samples)))\n",
    "                        # Find L(p(u))\n",
    "                        paf_interp = []\n",
    "                        for k in range(len(interp_coord)):\n",
    "                            paf_interp.append([pafA[int(round(interp_coord[k][1])), int(round(interp_coord[k][0]))],\n",
    "                                               pafB[int(round(interp_coord[k][1])), int(round(interp_coord[k][0]))] ]) \n",
    "                        # Find E\n",
    "                        paf_scores = np.dot(paf_interp, d_ij)\n",
    "                        avg_paf_score = sum(paf_scores)/len(paf_scores)\n",
    "\n",
    "                        # Check if the connection is valid\n",
    "                        # If the fraction of interpolated vectors aligned with PAF is higher then threshold -> Valid Pair  \n",
    "                        if ( len(np.where(paf_scores > paf_score_th)[0]) / n_interp_samples ) > conf_th :\n",
    "                            if avg_paf_score > maxScore:\n",
    "                                max_j = j\n",
    "                                maxScore = avg_paf_score\n",
    "                                found = 1\n",
    "                    # Append the connection to the list\n",
    "                    if found:            \n",
    "                        valid_pair = np.append(valid_pair, [[candA[i][3], candB[max_j][3], maxScore]], axis=0)\n",
    "\n",
    "                # Append the detected connections to the global list\n",
    "                valid_pairs.append(valid_pair)\n",
    "            else: # If no keypoints are detected\n",
    "                #print(\"No Connection : k = {}\".format(k))\n",
    "                invalid_pairs.append(k)\n",
    "                valid_pairs.append([])\n",
    "        #print(valid_pairs)\n",
    "        return valid_pairs, invalid_pairs\n",
    "\n",
    "    # This function creates a list of keypoints belonging to each person\n",
    "    # For each detected valid pair, it assigns the joint(s) to a person\n",
    "    # It finds the person and index at which the joint should be added. This can be done since we have an id for each joint\n",
    "    def getPersonwiseKeypoints(valid_pairs, invalid_pairs):\n",
    "        # the last number in each row is the overall score \n",
    "        personwiseKeypoints = -1 * np.ones((0, 19))\n",
    "\n",
    "        for k in range(len(mapIdx)):\n",
    "            if k not in invalid_pairs:\n",
    "                partAs = valid_pairs[k][:,0]\n",
    "                partBs = valid_pairs[k][:,1]\n",
    "                indexA, indexB = np.array(POSE_PAIRS[k])\n",
    "\n",
    "                for i in range(len(valid_pairs[k])): \n",
    "                    found = 0\n",
    "                    person_idx = -1\n",
    "                    for j in range(len(personwiseKeypoints)):\n",
    "                        if personwiseKeypoints[j][indexA] == partAs[i]:\n",
    "                            person_idx = j\n",
    "                            found = 1\n",
    "                            break\n",
    "\n",
    "                    if found:\n",
    "                        personwiseKeypoints[person_idx][indexB] = partBs[i]\n",
    "                        personwiseKeypoints[person_idx][-1] += keypoints_list[partBs[i].astype(int), 2] + valid_pairs[k][i][2]\n",
    "\n",
    "                    # if find no partA in the subset, create a new subset\n",
    "                    elif not found and k < 17:\n",
    "                        row = -1 * np.ones(19)\n",
    "                        row[indexA] = partAs[i]\n",
    "                        row[indexB] = partBs[i]\n",
    "                        # add the keypoint_scores for the two keypoints and the paf_score \n",
    "                        row[-1] = sum(keypoints_list[valid_pairs[k][i,:2].astype(int), 2]) + valid_pairs[k][i][2]\n",
    "                        personwiseKeypoints = np.vstack([personwiseKeypoints, row])\n",
    "        return personwiseKeypoints\n",
    "\n",
    "\n",
    "    ###########################################\n",
    "    frameWidth = image1.shape[1]\n",
    "    frameHeight = image1.shape[0]\n",
    "\n",
    "    t = time.time()\n",
    "    \n",
    "\n",
    "    # Fix the input Height and get the width according to the Aspect Ratio\n",
    "    inHeight = 368\n",
    "    inWidth = int((inHeight/frameHeight)*frameWidth)\n",
    "\n",
    "    inpBlob = cv2.dnn.blobFromImage(image1, 1.0 / 255, (inWidth, inHeight),\n",
    "                              (0, 0, 0), swapRB=False, crop=False)\n",
    "\n",
    "    net.setInput(inpBlob)\n",
    "    output = net.forward()\n",
    "    detected_keypoints = []\n",
    "    keypoints_list = np.zeros((0,3))\n",
    "    keypoint_id = 0\n",
    "    threshold = 0.1\n",
    "    \n",
    "    #--- Also save keypoints in a dictionary\n",
    "    keypoints_dict = {}\n",
    "\n",
    "    for part in range(nPoints):\n",
    "        probMap = output[0,part,:,:]\n",
    "        probMap = cv2.resize(probMap, (image1.shape[1], image1.shape[0]))\n",
    "\n",
    "        keypoints = getKeypoints(probMap, threshold)\n",
    "        #print(\"Keypoints - {} : {}\".format(keypointsMapping[part], keypoints))\n",
    "        keypoints_with_id = []\n",
    "        for i in range(len(keypoints)):\n",
    "            keypoints_with_id.append(keypoints[i] + (keypoint_id,))\n",
    "            keypoints_list = np.vstack([keypoints_list, keypoints[i]])\n",
    "            keypoint_id += 1\n",
    "\n",
    "        detected_keypoints.append(keypoints_with_id)\n",
    "        \n",
    "    for kpointcollection in detected_keypoints:\n",
    "        if len(kpointcollection)>0:\n",
    "            for kpoint in kpointcollection:\n",
    "                keypoints_dict[kpoint[3]] = [kpoint[0], kpoint[1]]\n",
    "\n",
    "    #frameClone = image1.copy()\n",
    "    #for i in range(nPoints):\n",
    "    #    for j in range(len(detected_keypoints[i])):\n",
    "    #        cv2.circle(frameClone, detected_keypoints[i][j][0:2], 3, [0,0,255], -1, cv2.LINE_AA)\n",
    "    #plt.figure(figsize=[15,15])\n",
    "    #plt.imshow(frameClone[:,:,[2,1,0]])\n",
    "\n",
    "    valid_pairs, invalid_pairs = getValidPairs(output)\n",
    "    personwiseKeypoints = getPersonwiseKeypoints(valid_pairs, invalid_pairs)\n",
    "\n",
    "    #for i in range(17):\n",
    "    #    for n in range(len(personwiseKeypoints)):\n",
    "    #        index = personwiseKeypoints[n][np.array(POSE_PAIRS[i])]\n",
    "    #        if -1 in index:\n",
    "    #            continue\n",
    "    #        B = np.int32(keypoints_list[index.astype(int), 0])\n",
    "    #        A = np.int32(keypoints_list[index.astype(int), 1])\n",
    "    #        cv2.line(frameClone, (B[0], A[0]), (B[1], A[1]), colors[i], 3, cv2.LINE_AA)\n",
    "    \n",
    "    personCoords = {}\n",
    "    count = 0\n",
    "    for person in personwiseKeypoints:\n",
    "        getPersonArray = {}\n",
    "        if (person[0:19]==-1.).sum() <=6:\n",
    "            for i in range(18):\n",
    "                if person[i] == -1:\n",
    "                    getPersonArray[i] = [-1, -1]\n",
    "                else:\n",
    "                    getPersonArray[i] = keypoints_dict[person[i]]\n",
    "            personCoords[\"person\"+str(count)] = getPersonArray\n",
    "        count += 1\n",
    "    \n",
    "    return personCoords\n",
    "\n",
    "def getVideoData(videoDir, videoFile, videoID, start_frame=1, end_frame=-1, step=1):\n",
    "    cap = cv2.VideoCapture(videoDir + videoFile)\n",
    "    #success,image = cap.read()\n",
    "    file_to_write = open(\"../data/frames/\"+videoFile[:-4]+\"_\"+str(start_frame)+\".json\", \"w\")\n",
    "    \n",
    "    count = 1\n",
    "    success = True\n",
    "    while success:\n",
    "        success,image = cap.read()\n",
    "        if count >= start_frame and count%step==0 and success:\n",
    "            persons = getPoseData(image)\n",
    "            \n",
    "            if len(persons) >0:\n",
    "                frame = {\n",
    "                    \"videoFile\":videoFile,\n",
    "                    \"videoID\":videoID,\n",
    "                    \"frame_no\":count,\n",
    "                    \"pers_coords\": persons,\n",
    "                    \"person_count\": len(persons.keys())\n",
    "                }\n",
    "            \n",
    "                file_to_write.write(json.dumps(frame)+\"\\n\")\n",
    "            \n",
    "        count += 1\n",
    "        \n",
    "        if end_frame != -1 and count>end_frame:\n",
    "            break\n",
    "        \n",
    "    file_to_write.close()\n",
    "    \n",
    "    \n",
    "    \n",
    "def getVideoData_List(videoDir, videoFile, videoID, list_frames=[]):\n",
    "    cap = cv2.VideoCapture(videoDir + videoFile)\n",
    "    #success,image = cap.read()\n",
    "    file_to_write = open(\"../data/frames/\"+videoFile[:-4]+\"_\"+str(videoID)+\".json\", \"w\")\n",
    "    count=0\n",
    "    for i in list_frames:\n",
    "        success,image = cap.read()\n",
    "        count += 1\n",
    "        if i == 1 and success:\n",
    "            persons = getPoseData(image)\n",
    "            \n",
    "            if len(persons) >0:\n",
    "                frame = {\n",
    "                    \"videoFile\":videoFile,\n",
    "                    \"videoID\":videoID,\n",
    "                    \"frame_no\":count,\n",
    "                    \"pers_coords\": persons,\n",
    "                    \"person_count\": len(persons.keys())\n",
    "                }\n",
    "            \n",
    "                file_to_write.write(json.dumps(frame)+\"\\n\")        \n",
    "    file_to_write.close()\n",
    "\n",
    "def getFrames(file_name, file_output, start_frame=0, end_frame=20, step=1):\n",
    "    cap = cv2.VideoCapture(file_name)\n",
    "    success,image = cap.read()\n",
    "    count = 0\n",
    "    success = True\n",
    "    while success:\n",
    "        success,image = cap.read()\n",
    "        if count > start_frame and count%step==0:\n",
    "            cv2.imwrite(file_output+\"%d.jpg\" % count, image)     # save frame as JPEG file\n",
    "            print('Read a new frame: ', success)\n",
    "        if count>end_frame:\n",
    "            break\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T02:14:09.418467Z",
     "start_time": "2019-11-25T02:14:08.725772Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n",
      "Read a new frame:  True\n"
     ]
    }
   ],
   "source": [
    "#vidDir = \"../data/vids/\"\n",
    "#getFrames(vidDir+\"QSgS8RIFZQA.mp4\", vidDir+\"QSgS8RIFZQA\", start_frame=1440, end_frame=1452)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T02:37:59.496017Z",
     "start_time": "2019-11-25T02:36:20.255856Z"
    }
   },
   "outputs": [],
   "source": [
    "#img_file = \"../data/vids/QSgS8RIFZQA1449.jpg\"\n",
    "#image1 = cv2.imread(img_file)\n",
    "#dictPoints = getPoseData(image1)\n",
    "#print(dictPoints)\n",
    "vidDir = \"../data/vids/\"\n",
    "getVideoData(vidDir, \"QSgS8RIFZQA.mp4\", \"QSgS8RIFZQA\", start_frame=1220, end_frame=1230)\n",
    "getVideoData(vidDir, \"QSgS8RIFZQA.mp4\", \"QSgS8RIFZQA\", start_frame=1584, end_frame=1600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T01:29:10.754249Z",
     "start_time": "2019-11-25T01:29:10.750463Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"person0\": {\"0\": [565, 66], \"1\": [573, 89], \"2\": [565, 88], \"3\": [-1, -1], \"4\": [-1, -1], \"5\": [581, 89], \"6\": [581, 113], \"7\": [573, 136], \"8\": [559, 129], \"9\": [564, 160], \"10\": [566, 191], \"11\": [573, 130], \"12\": [573, 160], \"13\": [573, 191], \"14\": [-1, -1], \"15\": [566, 66], \"16\": [-1, -1], \"17\": [575, 66]}, \"person1\": {\"0\": [215, 51], \"1\": [183, 81], \"2\": [197, 82], \"3\": [247, 105], \"4\": [285, 90], \"5\": [-1, -1], \"6\": [-1, -1], \"7\": [-1, -1], \"8\": [168, 176], \"9\": [160, 253], \"10\": [136, 315], \"11\": [153, 175], \"12\": [197, 238], \"13\": [182, 308], \"14\": [214, 49], \"15\": [-1, -1], \"16\": [199, 50], \"17\": [-1, -1]}, \"person2\": {\"0\": [66, 57], \"1\": [67, 73], \"2\": [57, 73], \"3\": [51, 97], \"4\": [75, 90], \"5\": [82, 73], \"6\": [89, 89], \"7\": [66, 91], \"8\": [59, 120], \"9\": [66, 152], \"10\": [66, 183], \"11\": [81, 114], \"12\": [81, 152], \"13\": [81, 183], \"14\": [66, 50], \"15\": [73, 50], \"16\": [58, 51], \"17\": [75, 51]}, \"person3\": {\"0\": [627, 57], \"1\": [627, 66], \"2\": [612, 66], \"3\": [605, 89], \"4\": [605, 105], \"5\": [637, 67], \"6\": [637, 88], \"7\": [-1, -1], \"8\": [612, 106], \"9\": [612, 137], \"10\": [612, 169], \"11\": [627, 106], \"12\": [621, 137], \"13\": [621, 174], \"14\": [627, 51], \"15\": [628, 51], \"16\": [620, 51], \"17\": [637, 57]}, \"person4\": {\"0\": [121, 43], \"1\": [121, 65], \"2\": [106, 66], \"3\": [105, 89], \"4\": [114, 104], \"5\": [137, 59], \"6\": [152, 74], \"7\": [145, 82], \"8\": [121, 113], \"9\": [127, 145], \"10\": [129, 183], \"11\": [137, 112], \"12\": [144, 144], \"13\": [144, 177], \"14\": [120, 42], \"15\": [127, 42], \"16\": [113, 43], \"17\": [129, 43]}, \"person5\": {\"0\": [409, 35], \"1\": [448, 58], \"2\": [471, 58], \"3\": [-1, -1], \"4\": [-1, -1], \"5\": [426, 58], \"6\": [371, 82], \"7\": [316, 81], \"8\": [471, 176], \"9\": [455, 238], \"10\": [456, 300], \"11\": [433, 176], \"12\": [409, 246], \"13\": [409, 325], \"14\": [-1, -1], \"15\": [410, 27], \"16\": [-1, -1], \"17\": [432, 20]}, \"person6\": {\"0\": [0, 57], \"1\": [0, 67], \"2\": [-1, -1], \"3\": [-1, -1], \"4\": [-1, -1], \"5\": [12, 67], \"6\": [19, 97], \"7\": [12, 74], \"8\": [0, 114], \"9\": [0, 152], \"10\": [-1, -1], \"11\": [11, 114], \"12\": [10, 152], \"13\": [10, 191], \"14\": [0, 51], \"15\": [10, 51], \"16\": [-1, -1], \"17\": [11, 51]}}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(dictPoints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T16:35:41.941852Z",
     "start_time": "2019-11-25T08:23:47.137353Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-5d78f9b795ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0msave_frame\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m#print((save_frame))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mgetVideoData_List\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvidDir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_frames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_frame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-61-3ada74d758c5>\u001b[0m in \u001b[0;36mgetVideoData_List\u001b[0;34m(videoDir, videoFile, videoID, list_frames)\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m             \u001b[0mpersons\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetPoseData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpersons\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-61-3ada74d758c5>\u001b[0m in \u001b[0;36mgetPoseData\u001b[0;34m(image1)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minpBlob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m     \u001b[0mdetected_keypoints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0mkeypoints_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "source=\"../data/vids/vid_source1.json\"\n",
    "vidDir = \"../data/vids/\"\n",
    "\n",
    "with open(source, \"r\") as f:\n",
    "    for line in f:\n",
    "        #print(line)\n",
    "        dict_source = json.loads(line)\n",
    "        #print(dict_source)\n",
    "        name = dict_source['filename']\n",
    "        ID = dict_source['ID']\n",
    "        len_times = len(list(dict_source[\"times\"].keys()))\n",
    "        save_frame = []\n",
    "        step = 3\n",
    "        for t in range(1, len_times+1):\n",
    "            frameTimes = dict_source[\"times\"][str(t)]\n",
    "            start = (frameTimes[0][0]*60 + frameTimes[0][1])*24\n",
    "            end = (frameTimes[1][0]*60 + frameTimes[1][1])*24\n",
    "            \n",
    "            save_frame += ((start-len(save_frame))*[0])\n",
    "            x = list(map(lambda x: int(x%step==0) , range(0, end-start)))\n",
    "            save_frame += x\n",
    "        #print((save_frame))\n",
    "        getVideoData_List(vidDir, name, ID, list_frames = save_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T07:32:29.107793Z",
     "start_time": "2019-11-25T07:32:29.100612Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start: 1200, end:1324, n:41, rem:2\n",
      "[1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "start = 1200\n",
    "end = 1324\n",
    "step = 3\n",
    "n = int((end-start)/step)\n",
    "rem = (start-end)%step\n",
    "print(f\"start: {start}, end:{end}, n:{n}, rem:{rem}\")\n",
    "x = list(map(lambda x: int(x%step==0) , range(0, 1324-1200)))\n",
    "print(x)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
